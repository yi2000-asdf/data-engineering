# Getting Started with Data Engineering

- [Модуль 01 - Роль Аналитики](https://github.com/Data-Learn/data-engineering/blob/master/DE%20-%20101%20Guide.md#%D0%BC%D0%BE%D0%B4%D1%83%D0%BB%D1%8C-1-%D1%80%D0%BE%D0%BB%D1%8C-%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D1%82%D0%B8%D0%BA%D0%B8-%D0%B2-%D0%BE%D1%80%D0%B3%D0%B0%D0%BD%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8)
- [Модуль 02 - Базы данных и SQL](https://github.com/Data-Learn/data-engineering/blob/master/DE%20-%20101%20Guide.md#%D0%BC%D0%BE%D0%B4%D1%83%D0%BB%D1%8C-2-%D0%B1%D0%B0%D0%B7%D1%8B-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85-%D0%B8-sql)

## Введение
Всем привет! Меня зовут Дмитрий Аношин. Спасибо, что нашли время ознакомиться с моим ресурсом. Надеюсь мой опыт поможет вам в достижение ваших целей и вы сможете приобрести новые знания и также помочь другим.

Вот уже 4 года я работаю дата инженером в Amazon. Когда я в 2016 году начинал работать на позиции data engineer, я особо не вдавался в подробности, что это за роль. Просто искал работу в области данных, желательно Business Intelligence разработчиком. А получилось найти позицию data engineer в Amazon. Частично мне повезло, частично это было заслуженно, так как с 2010 года я непрерывно учился и развивался в области аналитики. 

Я преследовал несколько целей:
1. Получать хорошую зарплату.
2. Работать в хорошей компании.
3. Работать за границей, желательно близко к морю или океану.

Поэтому очень важно на начальном этапе *определиться с целью*. Именно цель даст вам силы и мотивацию для её достижения. 

Сейчас очень много "мусора" в онлайне и в офлайне, все готовы вас научить. Обычно по принципу "утром деньги - вечером стулья": то есть сначала вы платите за курс, а там - как повезет. 

Сам я читал множество книг, смотрел обучающие видео и проходил курсы на Coursera и edX. И зачастую курс бывает "формальный", неинтересный, скучный. Я бы не хотел сделать еще один скучный курс, поэтому этот курс будет меняться и эволюционировать, у него могут появляться новые модули и изменяться старые.

Я не преследую цели научить всех и не преследую цели зарабатывать на студентах. Так сложилось, что за свою карьеру я помог 8-ми знакомым пройти путь с нуля до трудоустройства, и 6 из них до сих пор успешно работают с данными. 

Меня до сих пор спрашивают: как научиться, как начать? И чтобы не рассказывать снова и снова одно и то же многократно, я решил сконцентрировать эти знания на ресурсе `datalearn`. Я не являюсь супер-экспертом в какой-то области и всё, о чем я говорю, - это моё восприятие роли аналитики, данных и инструментов аналитики для помощи бизнесу. 

Как я уже говорил, курс бесплатный, так как он ничего не гарантирует. Но я уверен: он работает, так как позволит вам сфокусироваться на важном и отбросить всё лишнее, но при условии, что у вас есть цель и вы готовы реально поднапрячься, так как основная нагрузка ложится именно на ваши плечи. 

Также хотелось бы создать *экосистему* - не просто набор видео лекций и упражнений, но framework, в котором люди могут помогать друг другу с решением задач и упражнений и делиться опытом. Будет просто замечательно, если вы станете *data ambasador* и будете принимать участие в создании, исправлении и добавлении контента. 

Еще один важный для меня момент - это возможность делиться западным опытом с русскоязычным комьюнити, рассказывать о популярных на западе технологиях и решениях, помогать подготовиться собеседованию западную компанию, например в Амазон. 

Если задуматься над вопросом *"что самое ценное в курсе?"*, то я бы отметил 2 момента:
1. Понимание задачи бизнеса и умение подобрать правильную (оптимальную) технологию для ее достижения.
2. Понимание базовых принципов аналитики.

Если по результату курса вы сможете ответить на эти два вопроса, то остальное - уже дело техники и гугл вам в помощь.

По окончании курса планируются сертификаты для всех, кто успешно справится со всеми заданиями (промежуточными заданиями модулей и итоговым заданием). 
Итоговое задание будет включать в себя проект сквозной аналитики.



# Требования
Прежде всего нужно определиться с требованиями для комфортной работы с данными и похождении курса. Я могу выявить несколько ключевых компонетов:
- доступ в интернет;)
- желательно экран 15" и больше;
- желательно 16 Gb оперативки (мин 8 Gb), иначе будет тормозить;
- операционные системы Windows и Maс. Linux тоже подойдет;
- чтобы получить доступ к AWS, возможно, понадобится ввести номер банковской карты при регистрации (не раньше 4го модуля).
- slack - это месенджер, вы можете скачаеть его [тут](https://slack.com/intl/en-ca/downloads/);
- акаунт github (мы расскажем в 1й домашней работе как установить GitHub и для чего он используется)
- знание английского на уровне чтения;
- умение гуглить;)
- наличие социальной сети, чтобы рассказать о курсе;

Например, если вы не знаете Английский, но хотите работать в этой области, то вам следует начать его изучать и активно практиковать! 

# Подготовка к курсу по Data Engineering
Теперь давайте посмотрим на функцилнальные требования к инструментам и навыкам. Вы может не значни ничего из списка, а можете быть экспертам по всем указанным инструментам.

Есть некоторые вещи, которые важно (или как минимум желательно) знать для успешного прохождения курса. 
Во время курса мы будем их разбирать, но будет хорошо, если вы уже владеете начальными навыками:

- **Excel**. Это универсальный инструмент для работы с данными. Если вы никогда с ним не работали, найдите любой ресурс и потренируйтесь. Страница Excel - это таблица со строками и столбцами, в которых можно выполнять операции над данными. Отличная аналогия для баз данных и хранилищ данных. Также в Excel можно создавать графики и Pivot (вы знаете, что это?) - это уже как BI инструмент.

- **SQL**. Самый важный для меня элемент. Чтобы там ни говорили про Python/Scala/Java, большинство компаний (тот же Амазон) имеют базы данных. И бизнес-пользователи, и аналитики используют SQL для получения данных. Мне нравится ресурс `sql-ex.ru`. Там есть множество упражнений, достаточно сделать около 30, чтобы понять, как используются `SELECT`, `FROM`, `GROUP BY`, `ORDER BY`, `HAVING`, `UNION`, `JOIN`, подзапросы. Этого хватит с головой! Есть и множество других ресурсов.

- **Python**. Так сложилось, что Python стал главный языком для инжиниринга данных, но не главнее SQL. С Python можно сделать все: от графика/отчета, до инструмента трансформации данных, Machine Learning модели и т.п. Я склоняюсь к тому, что Python - это уже следующий уровень, сначала надо знать SQL. Например, 80% моей работы Data Engineer - это использование SQL, так как данные либо в озере данных, либо в хранилище данных. В редких случаях нужен Spark (PySpark или Scala). 

- **CLI**. Command line interface, или командная строка. Это важный навык, так как зачастую программы установлены на Linux машинах без графического интерфейса (или на удалённых серверах), и нужно консольными  командами перемещаться по папкам и запускать программы. Вот отличный курс: [Introduction to Shell](https://www.datacamp.com/courses/introduction-to-shell-for-data-science).

- **GitHub**. Так как мы используем гитхаб как учебник, то обязательно посмотрите, как он работает. Сам по себе гит очень популярен для разработчиков, чтобы хранить код или делать code review (смотреть изменения в коде). Он хорошо работает для SQL, Python, но не работает для приложений вроде Tabelau и PowerBI. Вот [инструкция на русском](http://bi0morph.github.io/hello-world/).

```
Каждый модуль состоит из нескольких видео лекций. 
Какждый раздел включает в себя небольшую теорию и ссылку на видео лекцию. 
При необходимости мы также добавим ссылку на лабораторную работу или домашнее задание.
В конце каждого модуля небольшой опрос.
```

# Модуль 1: Роль Аналитики в Организации

## 1.1: Введение

Данный модуль направлен на получение теоретической базы знаний для дальнейшей работы с курсом, а также на понимание роли аналитики и дата инженера в организации. Прежде чем научиться работать с инструментами очень важно понять принцип работы бизнеса, как бизнес использует данные, и как они могут быть полезны. Будут рассмотрены типовые архитектурные решения и вакансии на роль дата инженера.

**Видео лекция** - [Модуль 1.1 Введение](https://youtu.be/UjvN8IE77Cs)

## 1.2: Роль аналитики в организации 

Организация существует для того, чтобы приносить какую-либо ценность (value). Выделяют 3 ключевых группы, кому именно может быть полезен тот или иной бизнес: 

1. Владельцы бизнеса (shareholders); 

2. Сотрудники (employees); 

3. Клиенты (customers). 


![Analytics Value Chain](https://rockyourdata.cloud/wp-content/uploads/2019/02/Screen-Shot-2019-02-11-at-8.58.28-PM.png)

Самая важная группа это клиенты, так как многие современные компании работают по принципу "customer obsession" (одержимость клиентом).

Для того чтобы бизнес рос нужно создавать больше ценностей для каждой из групп. Для клиентов, например, клиентский опыт (customer experience). Для сотрудников - уровень баланса между работой и жизнью, зарплата (work life balance, salary). Для владельцев - доход (income). Для успешного роста бизнеса и выполнения своей работы все эти группы принимают решения (decision making). Для того чтобы принимать решения нужны данные (data). Данные могут быть в необработанном виде (raw data), а могут быть в виде информации (organized raw data). Одной из задач инженера данных является предоставление данных группам, которые были описаны выше для принятия дальнейших решений. Поэтому очень важно понимать, как именно работа проделанная дата инженером влияет на то, что происходит с бизнесом.

**Видео лекция** - [Модуль 1.2 Роль Аналитики в Организации](https://youtu.be/DpXQSsKhWcs)

## 1.3: Задачи аналитики

Аналитика это такая часть бизнеса, которая использует данные для получения информации, на основе которой принимаются решения для эффективной работы бизнеса. Аналитика нужна для: 

1. Повышение прибыли. Если аналитическое решение помогает зарабатывать деньги, то всё хорошо если нет, то где-то есть проблема; 
2. Снижение расходов. Мониторинг расходов помогает экономить деньги; 
3. Исследование новых рынков или продуктов 
4. Соблюдение требований 
5. Избежание рисков

**Видео лекция** - [Модуль 1.3 Роль Аналитики в Организации](https://youtu.be/80zFSlm9w0w)

## 1.4: MindMap инжиниринга данных

MindMap - интеллектуальная карта, инструмент визуального отображения информации. 

![Mindmap](https://user-images.githubusercontent.com/65634544/83002336-4a252e80-a050-11ea-884a-aad96a181f74.jpg)

1. Интеграция данных. ETL/ELT- извлечение (extract), трансформирование (transform), загрузка (load); 
2. Хранилище данных (Data Warehouse)/Платформа данных (Data Platform) - современное хранилище данных/Озеро данных (data lake) - файловое хранилище. Data platform = Data Lake + DW; 
3. Облако (cloud) - облачная аналитика; 
4. Batch - загрузка данных пачками, так работает классический ETL/ELT инструмент/Stream - непрерывный поток данных;
5. Бизнес - аналитика (Business Intelligence) - прослойка между IT и бизнес пользователем;
6. SQL (Structured Query Language)
7. Языки программирования такие как: Python, Scala, Java;
8. MPP (Massive Parallel Processing) - архитектурная особенность аналитических хранилищ данных;
9. Big Data;
10. Spark - быстрая и универсальная платформа для обработки данных

**Видео лекция** - [Модуль 1.4 MindMap Инженера Данных](https://youtu.be/tqs8Vn8bSMs)

## 1.5: Основные роли в аналитике

### Традиционная категория:
1. BI разработчик. Работа с отчётами, дашбордами, внедрением решений BI (Tableau, Power BI, SAP). Часто в обязанности входит предоставление бизнес-рекомендаций (business insights);
2. ETL/ELT. Работа с интеграцией ("технари");
3. Разработчик отчётов = BI инженер;
4. DW разработчик/архитектор. Работа с решением и его архитектурой (как она выглядит и что делает);
5. Data Modeller. Работа с бизнес-процессами организации и созданием модели данных, по которой будет создано будущее хранилище данных.

### Категория инженера данных:
1. Data Engineer (классическое понимание инженера данных);
2. Big Data инженер. Работа с решениями, связанными с нереляционными БД;
3. Cloud DE. Работа с решениями в облаке;
4. Data Platform инженер. Работа с решениями, связанными с хранилищем данных и озером данных.

### Профильная категория (Data Science, IT):
1. Разработчик программного обеспечения (Software Development Engineer). Хорошее знание алгоритмов, структур данных. Иногда работа связана с Big Data;
2. Machine Learning Engineer. Хорошее знание математики, программирования и библиотек, каркаса для deep learning ;
3. Visual Engineer. Работа с визуализацией данных с использованием языков программирования.
4. Applied Scientist 
5. Research Scientist

### Категория продвинутая аналитика (Элементы прогнозирования):
1. Data mining. Роль до Data science;
2. Data science. Хорошее знание математики, статистики, программирования;
3. Аналитик данных = Data science.

Курс практически полностью покрывает традиционную категорию и категорию инженера данных.

**Видео лекция** - [Модуль 1.5 Основные роли и профессии для работы с данными](https://youtu.be/5OkCvQOF3Wg)

## 1.6: Два типа инженера данных
Мне очень нравится слово ИНЖЕНЕР. Я сам по специальности Инженер-конструктор. Для меня инженер - это профессионал, который может посмотреть на предмет и мысленно его разобрать на составные части, найти неисправность в неработающем предмете или создать новый предмет на базе требований заказчика, используя свои профессиональные инструменты. 

Инженер не знает всё обо всём, он понимает базовые принципы и видит конечную цель, а дальше с использованием инструментария и навыков он творит.

Инженеры бывают разные, мы будет говорить про инженеров, которые работают с данными. Не знаю, как у вас, но до Амазона я термин *data engineer* не использовал, вместо инженера были просто *разработчики* и *специалисты*:
- Разработчик ПО
- Разработчик Отчетов
- Специалист data mining
- BI Разработчик
- ETL разработчик
- DW разработчик

И еще были *архитекторы*: все те же слова, но с дополнением "архитектор" - это значит уже опытный специалист, который может не просто что-то делать, но и создавать архитектуру решения (DW, BI, ETL).

Прежде всего, для меня существует два типа Инженера Данных:
1.	Программист, который стал Инженером Данных.
2.	BI/DW/ETL-разработчик, который стал Инженером Данных.

Давайте подробнее рассмотрим отличия. Задача Инженера Данных - создание платформы, куда автоматически загружаются данные, там они трансформируются в доступную форму для конечных пользователей (как правило, бизнес-пользователей). 

Источники данных могут быть различными: реляционные базы данных, SFTP, API, файлы с логами, сенсоры. Типа данных также могут быть различными: структурированные данные в табличном формате, полуструктурированные (JSON, XML) и неструктурированные (видео, аудио).

В зависимости от бизнес-требований, Инженеру Данных необходимо создать поток данных (data pipeline), который автоматически будет забирать данные и загружать их в платформу данных (хранилище данных или озеро данных). Вам необходимо выбрать инструменты для работы с данными. 

Цель у нас простая: помочь бизнесу извлечь ценную информацию из данных. Для этого нужно создать аналитическое решение, где пользователи могут самостоятельно работать с данными, проверять свои гипотезы и анализировать бизнес-задачи, используя правильные метрики. 

Чтобы построить такое решение, нужен Инженер Данных. В моем случает это не просто создание потока данных, трансформация и загрузка данных. Это полноценная работа с бизнес-подразделениями, понимание их нужд и предоставление им инструментов для решения их задач. 

Я имею в виду весь цикл построения аналитического решения. Именно это мы будем изучать на курсе. 

И теперь самое интересное: в зависимости от вашего опыта, вы можете использовать языки программирования Java/Python и т.д. для создания решения - Инженер Данных №1 (*Technical Data Engineer*), а можете использовать готовые решения, которые позволят вам создавать масштабируемые и безопасные решения, быстро достигать результатов - Инженер Данных №2 (пусть будет *Result Oriented Data Engineer*). 

Без программирования не обойтись даже для 2-го типа, но вам не нужно быть гуру программирования, достаточно понимать, как работает Python, и использовать небольшие куски кода для кастомизации решения. 

**Главное в этом курсе не зубрежка программирования или конкретного продукта, а понимание принципов работы с данными, классов инструментов и возможных бизнес-задач и пути их решения, а для всего остального есть Google;)**

**Видео лекция** - [Модуль 1.6 Два типа инженера данных](https://youtu.be/Ei21wxKKCMI)

## 1.7: Архитектура аналитического решения

![Overall-Architecture](https://user-images.githubusercontent.com/65634544/83002262-2feb5080-a050-11ea-93f1-3fe6196c973a.png)

**3 слоя архитектуры:**
1. `Source Layer` - слой систем источников данных OLTP (Online Transactional Processing) - обработка транзакций; системы быстро работают на добавление данных в БД, но не рассчитаны на аналитические запросы; как правило данные создаются бизнес процессами; из первого слоя все данные поступают  в хранилище данных;

2. `Storage Layer` - хранение данных для аналитики (DW, Data Lake, Data Platform); в хранилище данных желательно иметь два слоя: Staging - копия всех данных из первого слоя вместе; BL - модель данных;

3. `Business Layer` - слой доступа к данным для бизнес пользователей через инструменты BI (Tableau, Power BI, SAP BO, Excel, QlikView) или SQL. Происходит подключение к системам для просмотра отчётов. 

Иногда используется ещё один слой - Processing/Compute Layer, где происходит трансформация данных перед загрузкой в хранилище.

**Видео лекция** - [Модуль 1.7 Архитектура Аналитического Решения](https://youtu.be/_M8yxr2Inyo)

## 1.8: Обзор вакансий Amazon и hh.ru

Мы рассмотрим самые популярные сайты для поиска работы. Эта лекция не обязательная.

**Заморские**
- indeed.com/worldwide - можно выбрать любую страну
- linkedin.com - качественные вакансии (нет мусора)
- amazon.jobs - вакансии Амазон

**Отечественные**
- hh.ru

В видео мы рассмотрели примеры вакансий Data Engineer, BI Engineer, ETL разработчик, BI Разработчик, Аналитик. Так же я показал на что я обращаю внимания и как можно определить тип решения, которое используется в компании.

**Видео лекция** - [Модуль 1.8 Обзор вакансий](https://youtu.be/A18WOwkInoQ)

## 1.9: Аналитика в Excel

Это лекция для людей, кто с excel "на вы". Мы рассмотрим примерые таблиц и основные операции, которыем можно выполнять в Excel. Чтобы успешно освоить профессию связанныую с аналитикой, нужно освоить Excel, так как там используются теже принципы работы с данными.

Эта лекция не обязательная.

**Видео лекция** - [Модуль 1.9 Аналитика в Excel](https://youtu.be/3ncC-l-nkOo)

## Домашнее задание
В качестве домашнего задания нужно установить `git`, создать аккаунт на `GitHub`, нарисовать архитектуру решения в `drawio` и построить дашборд на базе файлика, который нужно синхронизировать со своим локальным компьютером, используя `git`. 

Всю необходимую информацию вы найдете в [/DE-101/Module-01/Lab/readme.md](https://github.com/Data-Learn/data-engineering/blob/master/DE-101/Module-01/Lab/readme.md).

Если у вас не получится использовать Git, то вы можете скачать все через веб интерфейс.

## Опрос Модуль 1
Пожалуйста пройдите [опрос по заврешению Модуля 1](https://forms.gle/PBHpWA2g2cNpEXax9). Так я смогу посмотреть, сколько человек закончило модуль, что было хорошо, а что можно улучшить.

# Модуль 2: Базы данных и SQL
Познакомимся с базами данных, и поймем их преимущество для работы с данными по сравнению с Excel/Google Sheets. 
Потренируемся на SQL, установим базу данных и загрузим в нее данные, потом будем использовать Excel/Google Sheets для визуализации данных.

## 2.1 Введение
**Видео лекция** - [Введение](https://youtu.be/GFgKx4XodMU)

## 2.2: Что такое базы данных и как они помогают при работе с данными

**Видео лекция часть 1 - теория** - [Что такое база данных](https://youtu.be/Y8kAHcpImNA).

**Видео лекция часть 2 - практика** [Установка Postgres](https://www.youtube.com/watch?v=Y8kAHcpImNA&t=507s).

### Дополнительные материалы для изучения
1. [Введение в Базы Данных](https://stepik.org/course/551/) (Русский)
2. [Хранилище данных vs Озеро Данных](https://habr.com/ru/post/485180/) (Русский)

### Практика
1. Вам необходимо установить Postgres базу данных к себе на компьютер. Вы можете посмотреть [инструкции по установки Postgres](https://github.com/Data-Learn/data-engineering/blob/master/how-to/%20How%20to%20install%20PostgreSQL.md). 

## 2.3: Подключение к Базам Данных и SQL


**Видео лекция часть 1 - теория** - [Подключение к БД](https://youtu.be/nJsRJ5SytjI). 

**Видео лекция часть 2 - практика** - [Подключение к БД, загрузка данных в БД, SQL запросы ](https://youtu.be/nJsRJ5SytjI?t=657)

### Дополнительные материалы для изучения
1. [Интерактивный онлайн-курс по SQL СУБД PostgreSQL](https://learndb.ru/) (Русский)
2. [Интерактивный SQL учебник с упражнениями](https://sql-ex.ru/) (Русский)
3. [Основные функции SQL](https://khashtamov.com/ru/window-functions-sql/) (Русский)
4. [Практика SQL](https://towardsdatascience.com/sqlzoo-the-best-way-to-practice-sql-66b7ccb1f17a) (English)
5. [SQL: Analyzing Business Metrics](https://www.codecademy.com/learn/sql-analyzing-business-metrics) (English)
6. [Analyze data with SQL](https://www.codecademy.com/learn/paths/analyze-data-with-sql) (English)
7. [Большой курс SQL и Баз Данных от Stanford](https://www.edx.org/course/databases-5-sql) (English)
8. [Интерактивный тренажер по SQL](https://stepik.org/course/63054/) (Русский)

### Практика
1. Вам необходимо установить клиент SQL для подключения базы данных. Вы можете посмотреть [инструкции по установки DBeaver](https://github.com/Data-Learn/data-engineering/blob/master/how-to/%20How%20to%20install%20DBeaver.md). Так же вы можете использовать любой другой клиент для подключения к ваше БД.
2. Создайте 3 таблицы и загрузите данные из [Superstore Excel файл](https://github.com/Data-Learn/data-engineering/blob/master/DE-101/Module-01/Lab/Sample%20-%20Superstore.xls) в вашу базу данных. Сохраните в вашем GitHub скрипт загрузки данных и создания таблиц. Вы можете использовать готовый [пример sql файлов](https://github.com/Data-Learn/data-engineering/tree/master/DE-101/Module-02/Lab).
3. Напишите запросы, чтобы ответить на вопросы из [Модуля 01](https://github.com/Data-Learn/data-engineering/tree/master/DE-101/Module-01/Lab#%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D1%82%D0%B8%D0%BA%D0%B0-%D0%B2-excel). Сохраните в вашем GitHub скрипт загрузки данных и создания таблиц. 

## 2.4: Модели Данных 

**Видео лекция часть 1 - теория** - [Модели Данных](https://youtu.be/Jwefn9G2I_g). 

**Видео лекция часть 2 - практика** - [Создание модели данных в SQLdbm](https://youtu.be/Jwefn9G2I_g?t=1903)

### Дополнительные материалы для изучения
1. Статья про Хранилище Данных [Антихрупкость архитектуры хранилищ данных](https://habr.com/ru/post/281553/)
2. Статья про Data Vault [Основы Data Vault](https://habr.com/ru/post/502968/)
### Практика
1. Вам необходимо нарисовать модель данных для нашего файлика [Superstore](https://github.com/Data-Learn/data-engineering/blob/master/DE-101/Module-01/Lab/Sample%20-%20Superstore.xls):
  - Концептуальную
  - Логическую
  - Физическую
Вы можете использовать бесплатную версию [SqlDBM](https://sqldbm.com/Home/) или любой другой софт для создания моделей данных баз данных.

2. Когда вы нарисуете модель данных, вам нужно скопировать DDL и выполнить его в SQL клиенте.
3. Вам немобходимо сделать `INSERT INTO SQL`, чтобы заполнить **Dimensions** таблицы и **Sales Fact** таблицу. Сначало мы заполняем **Dimensions** таблицы, где в качесте **id** мы генерим последовательность чисел, а зачем **Sales Fact** таблицу, в которую вставляем **id** из **Dimensions** таблиц. Такой пример я рассматривал в видео.

## 2.5: База данных в облаке

**Видео лекция часть 1 - теория** - [БД в облаке](https://youtu.be/UzILBlOAQ9s). 

**Видео лекция часть 2 - практика** - [Создание Аналитической БД в облаке AWS](https://youtu.be/UzILBlOAQ9s?t=627)

### Дополнительные материалы для изучения
Мы посвятим целый модуль облачным вычислениям. Но к сожалению, очень мало информации по сетевому администрированию, которую легко и быстро усвоить. Цель простая - нам необходимо, чтобы 2 и более сервера могли эффективно и безопасно коммуницировать между собой через сеть. Для этого нужно открыть/закрыть порты, настроить firewall и возможны другие действия. Вы можете поискать информацию.

1. Лекции на Coursera [Google IT Support Professional](https://www.coursera.org/professional-certificates/google-it-support) (English)
2. [Шпаргалка системного администратора по сетевым инструментам Linux](https://habr.com/ru/company/ruvds/blog/417485/) (Русский)

### Практика
1. Вам необходимо [создать учетную запись в AWS](https://github.com/Data-Learn/data-engineering/blob/master/how-to/How%20to%20create%20AWS%20Account.md). Это бесплатно. 
2. Используя сервис AWS Lightsail создайте БД Postgres и активируйте **Public access**
3. Подключитесь к новой БД через SQL клиент (например Dbeaver)
4. Загрузите данные из модуля 2.3 (Superstore dataset) в staging (схема БД `stg`) и загрузите dimensional model (схема `dw`). Вы можете использовать мой пример SQL для этого упражнения:
  - Staging [stg.orders.sql](https://github.com/Data-Learn/data-engineering/blob/master/DE-101/Module-02/Lab/stg.orders.sql)
  - Business Layer [from_stg_to_dw.sql](https://github.com/Data-Learn/data-engineering/blob/master/DE-101/Module-02/Lab/from_stg_to_dw.sql)
5. Попробуйте выполнить свои запросы из предыдущих упражнений. Не забдуть указать схему перед название таблицы. Например, `public.orders` или `stg.orders`.

## 2.6: Как донести данные до бизнес-пользователя (Пример решений на Klip Folio, Google Sheets и тп)

**Видео лекция часть 1 - теория** - [Сервисы визуализации для базы данных](https://youtu.be/bqUtv1y3D7A). 

**Видео лекция часть 2 - практика** - [Пример поделючения к облачным сервисам](https://youtu.be/bqUtv1y3D7A?t=825)

### Дополнительные материалы для изучения
Данная лекция знакомит вас с популярными сервисам для визуализации данных. Посути мы с вами создаем BI решение. Более детально мы рассмотрим про BI в модуле 3. 

1. [Введение в Google Data Studio](https://analytics.google.com/analytics/academy/course/10) (English)
2. [AWS QuickSight практика](https://docs.aws.amazon.com/quicksight/latest/user/getting-started.html) (English)
3. [Klipfolio практика](https://www.klipfolio.com/blogs-and-tutorials) (English)
4. [Пиратские метрики](https://vc.ru/trade/53154-piratskie-metriki-dlya-internet-magazina) (Русский)
5. [AARRR воронка — модель «Пиратские метрики» + фреймворк AAARRR](https://leadstartup.ru/db/aarrr) (Русский)
6. [Обзор книги «Lean Analytics»](https://gopractice.ru/lean_analytics/) Русский)

### Практика
В качестве домашнего задания вам необходимо создать дашборд в одном из решений, которые мы рассмотрели. ДЛя идей можно использовать задание из 1го модуля. Данные должны быть в Postgres в AWS и вы сможете подключиться сервисом к БД и создать несколько отчетов. Для практики можно и во всех 3х создать.

## Опрос Модуль 2
Пожалуйста пройдите [опрос по заврешению Модуля 2](https://forms.gle/GX2jPuvBxDNXa5dU9). Так я смогу посмотреть, сколько человек закончило модуль, что было хорошо, а что можно улучшить.

# Модуль 3: Визуализация данных, дашборды и отчетность - Business Intelligence.

## 3.1 Введение 

## 3.2 Что такое Business Intelligence (BI)

## 3.3 Обзор рынка решений BI

## 3.4 Основы Визуализации данных

## 3.5 Что такое Self-Service Analytics

## 3.6 Знакомимся с основными понятиями BI на примере Tableau Desktop (dimension, measure, filter, semantic layer и тд)

## 3.7 Знакомимся с с основными понятиями BI на примере Power BI

## 3.8 Зачем нужен BI Server и как он работает на пример Tableau Server

## 3.9 Основные задачи BI разработчика

# Модуль 4:  Интеграция данных и создание потоков данных (data piplelines)

## Модуль 4.1 Введение

## Модуль 4.2 Что такое ETL и ELT? 

## Модуль 4.3 Обзор рынка решений ETL

## Модуль 4.4 Классийческий ETL с графическим интерфейсом 

## Модуль 4.5 Техники хранилищ данных в ETL иснтрументах

## Модуль 4.6 Пример производительности ETL и ELT

# Модуль 5: Облачные вычисления (Cloud Computing)

# Модуль 6: Облачное Хранилище данных

# Модуль 7: Знакомство с Apache Spark

# Модуль 8: Создание решения для Big Data с использованием Hadoop и Spark

# Модуль 9: Знакомство с понятием Озера Данных и его создание с помощью инструментов AWS

# Модуль 10: Решение задачи по стримингу данных

# Модуль 11: Задачи Машинного Обучения глазами инженера данных

# Модуль 12: Лучшие практики инженера данных
